{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from scipy import spatial\n",
    "from pymfe.mfe import MFE\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result = {}\n",
    "json_result['datasets'] = []\n",
    "json_mfe_result = {}\n",
    "json_mfe_result['datasets'] = []\n",
    "onlyfiles = [f for f in listdir('RealDatasets') if isfile(join('RealDatasets', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfExistsInJson(data_name):\n",
    "    file = open('result.json')\n",
    "    d = json.load(file)\n",
    "    if('datasets' in d):\n",
    "            for p in d['datasets']:\n",
    "                if(p['name'] == data_name):\n",
    "                    print(\"Já tem!\")\n",
    "                    return True\n",
    "    return False    \n",
    "\n",
    "def build_json_object(dataset_name, default_params_result, best_params_result, params):\n",
    "    json_result['datasets'].append({\n",
    "        'name': dataset_name,\n",
    "        'default_params_result': default_params_result,\n",
    "        'best_params_result': best_params_result,\n",
    "        'params': {\n",
    "            'max_depth': params['max_depth'],\n",
    "            'min_child_weight': params['min_child_weight'],\n",
    "            'gamma': params['gamma'],\n",
    "            'subsample': params['subsample'],\n",
    "            'colsample_bytree': params['colsample_bytree']\n",
    "        }\n",
    "    })\n",
    "    \n",
    "def build_json_mfe_object(dataset_name, mfe):\n",
    "    json_mfe_result['datasets'].append({\n",
    "        'name': dataset_name,\n",
    "        'mfe': mfe\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfe_groups = ['general', 'statistical', 'info-theory']\n",
    "mfe_groups = ['info-theory']\n",
    "\n",
    "def mfe_extract(dataframe):\n",
    "    y = dataframe['target'].tolist()\n",
    "    X = dataframe.drop('target', axis=1).values\n",
    "    \n",
    "    mfe = MFE(mfe_groups)\n",
    "    mfe.fit(X, y)\n",
    "    ft = mfe.extract()\n",
    "    \n",
    "    result = {}\n",
    "    for i in range(0, len(ft[0])):\n",
    "        if(str(ft[1][i]) != 'nan'):\n",
    "            result[ft[0][i]] = np.float64(ft[1][i])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(dataframe):\n",
    "    estimator = xgb.XGBClassifier() \n",
    "    \n",
    "    X = dataframe[dataframe.columns[:-1]]\n",
    "    y = dataframe['target']\n",
    "    \n",
    "    k_folds = 5 \n",
    "    for i in df['target'].value_counts():\n",
    "        if(i < k_folds):\n",
    "            k_folds = i\n",
    "    \n",
    "    if(k_folds == 1):\n",
    "        return(0.0, 0.0, 0.0)\n",
    "#     Parâmetros reduzidos\n",
    "    parameters = {\n",
    "        'max_depth': range(3, 8, 1), # Maximum depth = more overfit\n",
    "        'min_child_weight': range(1, 3, 1), \n",
    "        'gamma': [0, 0.2, 0,5, 1],\n",
    "        'subsample': [0.2, 0.5, 1.0],\n",
    "        'colsample_bytree': [0.2, 0.5, 1.0]\n",
    "    }\n",
    "    \n",
    "    default_parameters = {\n",
    "        'max_depth': [6], \n",
    "        'min_child_weight': [1], \n",
    "        'gamma': [0],\n",
    "        'subsample': [1],\n",
    "        'colsample_bytree': [1]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=default_parameters,\n",
    "        cv=k_folds\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    default_value = grid_search.best_score_*100\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=parameters,\n",
    "        cv=k_folds\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    value = grid_search.best_score_*100\n",
    "    \n",
    "    # Default params accuracy / best params accuracy / params\n",
    "    return (default_value, value, grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(v1, v2):\n",
    "    return sum((p-q)**2 for p, q in zip(v1, v2)) ** .5\n",
    "\n",
    "def calculates_metafeature_similarity(listA, listB):\n",
    "    arrayAuxA = []\n",
    "    arrayAuxB = []\n",
    "        \n",
    "    for i in listA['mfe']:\n",
    "        for j in listB['mfe']:\n",
    "            if(i == j):\n",
    "                arrayAuxA.append(float(listA['mfe'][i]))\n",
    "                arrayAuxB.append(float(listB['mfe'][j]))\n",
    "                \n",
    "    return euclidean(arrayAuxA, arrayAuxB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  0  -  acute-inflammations_1556.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  1  -  allbp_40707.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  2  -  analcatdata_authorship_458.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  3  -  analcatdata_challenger_1013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  4  -  analcatdata_chlamydia_875.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  5  -  analcatdata_creditscore_461.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  6  -  analcatdata_germangss_1025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  7  -  analcatdata_happiness_40709.csv\n",
      "Dataset:  8  -  analcatdata_lawsuit_450.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  9  -  analcatdata_vineyard_724.csv\n",
      "Dataset:  10  -  analcatdata_wildcat_748.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  11  -  ar1_1059.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  12  -  ar4_1061.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  13  -  ar6_1064.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  14  -  autoPrice_756.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  15  -  autoUniv-au6-400_1551.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  16  -  autoUniv-au7-500_1554.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  17  -  auto_price_745.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  18  -  backache_463.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  19  -  badges2_1121.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  20  -  blogger_1463.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  21  -  blood-transfusion-service-center_1464.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  22  -  bodyfat_778.csv\n",
      "Dataset:  23  -  breast-cancer-dropped-missing-attributes-values_23499.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  24  -  breast-tissue_1465.csv\n",
      "Dataset:  25  -  breast-tissue_1559.csv\n",
      "Dataset:  26  -  calendarDOW_40663.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  27  -  car-evaluation_40664.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  28  -  cardiotocography_1466.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  29  -  cars1_40700.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  30  -  CastMetal1_1447.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  31  -  chatfield_4_820.csv\n",
      "Dataset:  32  -  chscase_census2_909.csv\n",
      "Dataset:  33  -  chscase_census3_908.csv\n",
      "Dataset:  34  -  chscase_census4_907.csv\n",
      "Dataset:  35  -  chscase_census5_906.csv\n",
      "Dataset:  36  -  chscase_census6_900.csv\n",
      "Dataset:  37  -  chscase_geyser1_895.csv\n",
      "Dataset:  38  -  chscase_vine2_814.csv\n",
      "Dataset:  39  -  clean1_40665.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  40  -  cleveland-nominal_40711.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  41  -  cleve_40710.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  42  -  cloud_860.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  43  -  collins_987.csv\n",
      "Dataset:  44  -  corral_40669.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  45  -  CostaMadre1_1446.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  46  -  dataset-autoHorse_fixed_42223.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  47  -  datatrieve_1075.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  48  -  desc_datasets.csv\n",
      "Dataset:  49  -  diggle_table_a2_818.csv\n",
      "Dataset:  50  -  ecoli_1011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  51  -  ecoli_39.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  52  -  ecoli_40671.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  53  -  Engine1_4340.csv\n",
      "Dataset:  54  -  fertility_1473.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  55  -  fri_c0_100_10_808.csv\n",
      "Dataset:  56  -  fri_c0_100_25_889.csv\n",
      "Dataset:  57  -  fri_c0_100_50_850.csv\n",
      "Dataset:  58  -  fri_c0_100_5_754.csv\n",
      "Dataset:  59  -  fri_c0_250_10_763.csv\n",
      "Dataset:  60  -  fri_c0_250_25_773.csv\n",
      "Dataset:  61  -  fri_c0_250_50_732.csv\n",
      "Dataset:  62  -  fri_c0_250_5_776.csv\n",
      "Dataset:  63  -  fri_c0_500_10_943.csv\n",
      "Dataset:  64  -  fri_c0_500_25_926.csv\n",
      "Dataset:  65  -  fri_c0_500_50_888.csv\n",
      "Dataset:  66  -  fri_c0_500_5_884.csv\n",
      "Dataset:  67  -  fri_c1_100_10_789.csv\n",
      "Dataset:  68  -  fri_c1_100_25_812.csv\n",
      "Dataset:  69  -  fri_c1_100_50_876.csv\n",
      "Dataset:  70  -  fri_c1_100_5_829.csv\n",
      "Dataset:  71  -  fri_c1_250_10_935.csv\n",
      "Dataset:  72  -  fri_c1_250_25_746.csv\n",
      "Dataset:  73  -  fri_c1_250_50_769.csv\n",
      "Dataset:  74  -  fri_c1_250_5_730.csv\n",
      "Dataset:  75  -  fri_c1_500_10_824.csv\n",
      "Dataset:  76  -  fri_c1_500_25_779.csv\n",
      "Dataset:  77  -  fri_c1_500_50_766.csv\n",
      "Dataset:  78  -  fri_c1_500_5_870.csv\n",
      "Dataset:  79  -  fri_c2_100_10_762.csv\n",
      "Dataset:  80  -  fri_c2_100_25_775.csv\n",
      "Dataset:  81  -  fri_c2_100_50_922.csv\n",
      "Dataset:  82  -  fri_c2_100_5_726.csv\n",
      "Dataset:  83  -  fri_c2_250_10_830.csv\n",
      "Dataset:  84  -  fri_c2_250_25_794.csv\n",
      "Dataset:  85  -  fri_c2_250_50_877.csv\n",
      "Dataset:  86  -  fri_c2_250_5_911.csv\n",
      "Dataset:  87  -  fri_c2_500_10_869.csv\n",
      "Dataset:  88  -  fri_c2_500_25_879.csv\n",
      "Dataset:  89  -  fri_c2_500_50_920.csv\n",
      "Dataset:  90  -  fri_c2_500_5_792.csv\n",
      "Dataset:  91  -  fri_c3_100_10_783.csv\n",
      "Dataset:  92  -  fri_c3_100_25_768.csv\n",
      "Dataset:  93  -  fri_c3_100_50_716.csv\n",
      "Dataset:  94  -  fri_c3_100_5_916.csv\n",
      "Dataset:  95  -  fri_c3_250_10_793.csv\n",
      "Dataset:  96  -  fri_c3_250_25_832.csv\n",
      "Dataset:  97  -  fri_c3_250_50_873.csv\n",
      "Dataset:  98  -  fri_c3_250_5_744.csv\n",
      "Dataset:  99  -  fri_c3_500_10_936.csv\n",
      "Dataset:  100  -  fri_c3_500_25_896.csv\n",
      "Dataset:  101  -  fri_c3_500_50_937.csv\n",
      "Dataset:  102  -  fri_c3_500_5_749.csv\n",
      "Dataset:  103  -  fri_c4_100_100_828.csv\n",
      "Dataset:  104  -  fri_c4_100_10_878.csv\n",
      "Dataset:  105  -  fri_c4_100_25_868.csv\n",
      "Dataset:  106  -  fri_c4_100_50_932.csv\n",
      "Dataset:  107  -  fri_c4_250_100_834.csv\n",
      "Dataset:  108  -  fri_c4_250_10_863.csv\n",
      "Dataset:  109  -  fri_c4_250_25_933.csv\n",
      "Dataset:  110  -  fri_c4_250_50_918.csv\n",
      "Dataset:  111  -  fri_c4_500_100_742.csv\n",
      "Dataset:  112  -  fri_c4_500_10_855.csv\n",
      "Dataset:  113  -  fri_c4_500_25_838.csv\n",
      "Dataset:  114  -  fri_c4_500_50_805.csv\n",
      "Dataset:  115  -  fruitfly_714.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  116  -  glass_1005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  117  -  glass_41.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  118  -  haberman_43.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  119  -  hayes-roth_329.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  120  -  hayes-roth_974.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  121  -  heart-h_1565.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  122  -  heart-long-beach_1512.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  123  -  heart-statlog_53.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  124  -  heart-switzerland_1513.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  125  -  ionosphere_59.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  126  -  iris_61.csv\n",
      "Dataset:  127  -  jEdit_4.0_4.2_1073.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  128  -  jEdit_4.2_4.3_1048.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  129  -  kc1-binary_1066.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  130  -  kc1-top5_1045.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  131  -  kc3_1065.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  132  -  KnuggetChase3_1448.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  133  -  KungChi3_1441.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  134  -  leaf_1482.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  135  -  LED-display-domain-7digit_40496.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  136  -  lowbwt_941.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  137  -  machine_cpu_733.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  138  -  mc2_1054.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  139  -  MeanWhile1_1449.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  140  -  mfeat-fourier_14.csv\n",
      "Dataset:  141  -  mfeat-karhunen_16.csv\n",
      "Dataset:  142  -  mfeat-pixel_40979.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  143  -  MindCave2_1450.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  144  -  monks-problems-2_334.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  145  -  mu284_880.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  146  -  mux6_40681.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  147  -  mw1_1071.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  148  -  no2_886.csv\n",
      "Dataset:  149  -  parkinsons_1488.csv\n",
      "Dataset:  150  -  pc1_req_1167.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  151  -  planning-relax_1490.csv\n",
      "Dataset:  152  -  plasma_retinol_915.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  153  -  pm10_750.csv\n",
      "Dataset:  154  -  prnn_fglass_952.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  155  -  prnn_fglass_996.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  156  -  prnn_synth_464.csv\n",
      "Dataset:  157  -  pwLinear_721.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  158  -  qsar-biodeg_1494.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  159  -  qualitative-bankruptcy_1495.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  160  -  rabe_266_782.csv\n",
      "Dataset:  161  -  rmftsa_sleepdata_679.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  162  -  robot-failures-lp4_1519.csv\n",
      "Dataset:  163  -  robot-failures-lp5_1520.csv\n",
      "Dataset:  164  -  sa-heart_1498.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  165  -  seeds_1499.csv\n",
      "Dataset:  166  -  seismic-bumps_1500.csv\n",
      "Dataset:  167  -  servo_747.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  168  -  sleuth_case2002_902.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  169  -  Smartphone-Based_Recognition_of_Human_Activities_4153.csv\n",
      "Dataset:  170  -  solar-flare_40686.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  171  -  sonar_40.csv\n",
      "Dataset:  172  -  SPECTF_1600.csv\n",
      "Dataset:  173  -  SPECTF_337.csv\n",
      "Dataset:  174  -  SPECT_336.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  175  -  steel-plates-fault_1504.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  176  -  synthetic_control_377.csv\n",
      "Dataset:  177  -  tae_48.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  178  -  tae_955.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  179  -  teachingAssistant_1115.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  180  -  tecator_851.csv\n",
      "Dataset:  181  -  thoracic-surgery_1506.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  182  -  thyroid-allhypo_40476.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  183  -  thyroid-new_40682.csv\n",
      "Dataset:  184  -  transplant_885.csv\n",
      "Dataset:  185  -  triazines_788.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  186  -  TuningSVMs_41976.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  187  -  TuningSVMs_41977.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  188  -  user-knowledge_1508.csv\n",
      "Dataset:  189  -  vertebra-column_1524.csv\n",
      "Dataset:  190  -  veteran_719.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  191  -  vinnie_860.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  192  -  visualizing_environmental_736.csv\n",
      "Dataset:  193  -  visualizing_galaxy_925.csv\n",
      "Dataset:  194  -  wholesale-customers_1511.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  195  -  wine-quality-red_40691.csv\n",
      "Dataset:  196  -  wine_187.csv\n",
      "Dataset:  197  -  wine_973.csv\n",
      "Dataset:  198  -  wisconsin_753.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  199  -  yeast_181.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  200  -  zoo_965.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: It is not possible make equal discretization\n"
     ]
    }
   ],
   "source": [
    "# Descomentar para rodar o código Xgboost + Mfe + Colocar no json\n",
    "\n",
    "# Dataset Dataset:  46  -  dataset-autoHorse_fixed_42223.csv com problema\n",
    "# Dataset 48 tambem\n",
    "for i in range(0, len(onlyfiles)):\n",
    "    print('Dataset: ', i, ' - ', onlyfiles[i])\n",
    "    path = ('RealDatasets/' + onlyfiles[i])\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [*df.columns[:-1], 'target']\n",
    "    \n",
    "    result = xgboost(df)\n",
    "    mfe = mfe_extract(df)\n",
    "\n",
    "    if(checkIfExistsInJson(onlyfiles[i]) == False and result[0] != 0):\n",
    "        build_json_object(onlyfiles[i], result[0], result[1], result[2])\n",
    "        build_json_mfe_object(onlyfiles[i], mfe)\n",
    "        \n",
    "    build_json_mfe_object(onlyfiles[i], mfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.json', 'w') as outfile:\n",
    "    json.dump(json_result, outfile)\n",
    "with open('mfe_result.json', 'w') as outfile:\n",
    "    json.dump(json_mfe_result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda parte - Testando os hiperparâmetros entre os datasets\n",
    "import copy\n",
    "file = open('result.json')\n",
    "file_mfe = open('mfe_result.json')\n",
    "data = json.load(file)\n",
    "data_mfe = json.load(file_mfe)\n",
    "estimator = xgb.XGBClassifier()\n",
    "optimized_datasets = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testHyperparams(dataframe, data):\n",
    "    params = data['params']\n",
    "    \n",
    "#     print('Params: ', params)\n",
    "    \n",
    "    X = dataframe[dataframe.columns[:-1]]\n",
    "    y = dataframe['target']\n",
    "    \n",
    "    for i in params:\n",
    "        if(type(params[i]) != type([])):\n",
    "            params[i] = [(params[i])]\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = estimator,\n",
    "        param_grid = params\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    answer = grid_search.best_score_*100\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def getDatasetInfo(name):\n",
    "    d = ''\n",
    "    for p in data['datasets']:\n",
    "        if(p['name'] == name):\n",
    "            d = p\n",
    "    \n",
    "    return d\n",
    "\n",
    "def getDatasetMfeInfo(name):\n",
    "    d = ''\n",
    "    for p in data_mfe['datasets']:\n",
    "        if(p['name'] == name):\n",
    "            d = p\n",
    "    \n",
    "    return d\n",
    "\n",
    "def getHyperparamsMean(hyperparams):\n",
    "#     print('Hyper len: ', len(hyperparams))\n",
    "#     print('K: ', len(hyperparams))\n",
    "#     print('Original: ', hyperparams)\n",
    "#     params_mean = hyperparams[0]['params']\n",
    "    params_mean = copy.deepcopy(hyperparams[0]['params'])\n",
    "# #     print(params_mean)\n",
    "    for i in range(1, len(hyperparams)):\n",
    "        params = hyperparams[i]['params']\n",
    "        for j in params:\n",
    "            params_mean[j][0] += params[j][0]\n",
    "    for i in params_mean:\n",
    "        params_mean[i][0] /= len(hyperparams)\n",
    "        if(i == 'max_depth'):\n",
    "            params_mean[i][0] = int(round(params_mean[i][0]))\n",
    "    \n",
    "#     print('media:', params_mean)\n",
    "# #     for i in hyperparams:\n",
    "# #         print(i['params'])\n",
    "# #         for j in i['params']:\n",
    "# #             print(j)\n",
    "    return {\"params\": params_mean}\n",
    "\n",
    "def getMode(a):\n",
    "    return max(set(a), key = a.count)\n",
    "\n",
    "def getHyperparamsMode(hyperparams):\n",
    "    params_mode = {\n",
    "        \"max_depth\": [],\n",
    "        \"min_child_weight\": [],\n",
    "        \"gamma\": [],\n",
    "        \"subsample\": [],\n",
    "        \"colsample_bytree\": []\n",
    "    }\n",
    "    \n",
    "    for i in hyperparams:\n",
    "        for j in i['params']:\n",
    "            params_mode[j].append(i['params'][j][0])\n",
    "            \n",
    "#     for i in teste:\n",
    "#         teste[i] = getMode([teste[i]])\n",
    "    \n",
    "    for i in params_mode:\n",
    "        params_mode[i] = [getMode(params_mode[i])]\n",
    "    \n",
    "    return {\"params\": params_mode}\n",
    "        \n",
    "\n",
    "def testMeanAndModeAllHyperparams(df, hyperparams):\n",
    "#     print(len(hyperparams))\n",
    "    result = []\n",
    "    hyperparams_mean = []\n",
    "    hyperparams_mode = []\n",
    "    \n",
    "    for i in range(0, len(hyperparams)):\n",
    "        atual = testHyperparams(df, getHyperparamsMean(hyperparams[0:i+1].copy()))\n",
    "        hyperparams_mean.append(atual)\n",
    "        atual = testHyperparams(df, getHyperparamsMode(hyperparams[0:i+1].copy()))\n",
    "        hyperparams_mode.append(atual)\n",
    "        \n",
    "#     print('Resultados para a média: ')\n",
    "#     for i in range(0, len(hyperparams_mean)):\n",
    "#         print(i, ' - ', hyperparams_mean[i])\n",
    "    \n",
    "#     print('Resultados para a moda: ')\n",
    "#     for i in range(0, len(hyperparams_mode)):\n",
    "#         print(i, ' - ', hyperparams_mode[i])\n",
    "    \n",
    "    return(hyperparams_mean, hyperparams_mode)\n",
    "        \n",
    "def testMeanAndModeGoodHyperparams(df, good_hyperparams):\n",
    "    result = []\n",
    "    hyperparams_mean = []\n",
    "    hyperparams_mode = []\n",
    "    \n",
    "    for i in range(0, len(good_hyperparams)):\n",
    "        atual = testHyperparams(df, getHyperparamsMean(good_hyperparams[0:i+1].copy()))\n",
    "        hyperparams_mean.append(atual)\n",
    "        atual = testHyperparams(df, getHyperparamsMode(good_hyperparams[0:i+1].copy()))\n",
    "        hyperparams_mode.append(atual)\n",
    "        \n",
    "    return(hyperparams_mean, hyperparams_mode)\n",
    "#     for i in good_hyperparams:\n",
    "#         print(i['params']['max_depth'])\n",
    "\n",
    "def getBestNHyperparams(name, n):\n",
    "    answer = []\n",
    "    ordem = []\n",
    "    d1 = getDatasetInfo(name)\n",
    "    d1_mfe = getDatasetMfeInfo(name)\n",
    "    \n",
    "    results = []\n",
    "    good_datasets = []\n",
    "    \n",
    "    for i in range(0, len(onlyfiles)):\n",
    "        d2 = getDatasetInfo(onlyfiles[i])\n",
    "        d2_mfe = getDatasetMfeInfo(onlyfiles[i])\n",
    "        \n",
    "        if(onlyfiles[i] == name):\n",
    "            continue\n",
    "            \n",
    "        if(d2):\n",
    "            ordem.append((calculates_metafeature_similarity(d1_mfe, d2_mfe), onlyfiles[i]))\n",
    "    \n",
    "    ordem.sort()\n",
    "    \n",
    "    qt = 0\n",
    "    \n",
    "    hyperparams = []\n",
    "    good_hyperparams = []\n",
    "    \n",
    "    path = ('RealDatasets/' + name)\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [*df.columns[:-1], 'target']\n",
    "    \n",
    "    j = 0\n",
    "    for i in ordem[:n]:\n",
    "        d2 = getDatasetInfo(i[1])\n",
    "        atual = testHyperparams(df, d2)\n",
    "        hyperparams.append(d2)\n",
    "#         print(i[0], ' - ', i[1])\n",
    "        \n",
    "        maior = False\n",
    "        if(float(atual) > float(d1['default_params_result'])):\n",
    "            maior = True\n",
    "            qt += 1\n",
    "        \n",
    "        if(maior == True):\n",
    "            good_hyperparams.append(d2)\n",
    "            \n",
    "#         print(atual, maior)\n",
    "        d = {\"name\": i[1],\n",
    "            \"distance\": i[0],\n",
    "            \"result_with_hiperparameter\": atual,\n",
    "            \"greater_than_default\": maior\n",
    "            }\n",
    "        \n",
    "#         d.update(sss)\n",
    "        \n",
    "        results.append(d)\n",
    "        j += 1\n",
    "        \n",
    "    \n",
    "#     print('\\nQuantidade de maiores que o default: ', qt)\n",
    "\n",
    "#     print(len(hyperparams))\n",
    "#     print(len(good_hyperparams))\n",
    "    \n",
    "    result_all_hyperparams = testMeanAndModeAllHyperparams(df, hyperparams)\n",
    "    result_good_hyperparams = testMeanAndModeGoodHyperparams(df, good_hyperparams)\n",
    "    \n",
    "#     for i in result_good_hyperparams:\n",
    "#         print(i)\n",
    "\n",
    "    results_according_k = []\n",
    "        \n",
    "    for i in range(0, len(result_all_hyperparams[0])):\n",
    "        results_according_k.append({\n",
    "            \"k\": i,\n",
    "            \"mean\": result_all_hyperparams[0][i],\n",
    "            \"mode\": result_all_hyperparams[1][i],\n",
    "            \"mean_good_datasets\": result_good_hyperparams[0][i] if i < len(result_good_hyperparams[0]) else -1,\n",
    "            \"mode_good_datasets\": result_good_hyperparams[1][i] if i < len(result_good_hyperparams[1]) else -1,\n",
    "        })\n",
    "\n",
    "    if(qt > 0):\n",
    "        global optimized_datasets\n",
    "        optimized_datasets += 1\n",
    "        \n",
    "        \n",
    "    best_mean_result = -1\n",
    "    best_mean_k_number = -1\n",
    "    best_mode_result = -1\n",
    "    best_mode_k_number = -1\n",
    "    best_mean_good_datasets = -1\n",
    "    best_mean_good_datasets_k_number = -1\n",
    "    best_mode_good_datasets = -1\n",
    "    best_mode_good_datasets_k_number = -1\n",
    "    best_result_using_hyperparameter_directly = -1\n",
    "    \n",
    "    for i in results:\n",
    "        best_result_using_hyperparameter_directly = max(best_result_using_hyperparameter_directly, i['result_with_hiperparameter'])\n",
    "    \n",
    "    for i in results_according_k:\n",
    "        if(i['mean'] > best_mean_result):\n",
    "            best_mean_result = i['mean']\n",
    "            best_mean_k_number = i['k']\n",
    "            \n",
    "        if(i['mode'] > best_mode_result):\n",
    "            best_mode_result = i['mode']\n",
    "            best_mode_k_number = i['k']\n",
    "            \n",
    "        if(i['mean_good_datasets'] > best_mean_good_datasets):\n",
    "            best_mean_good_datasets = i['mean_good_datasets']\n",
    "            best_mean_good_datasets_k_number = i['k']\n",
    "            \n",
    "        if(i['mean_good_datasets'] > best_mode_good_datasets):\n",
    "            best_mode_good_datasets = i['mode_good_datasets']\n",
    "            best_mode_good_datasets_k_number = i['k']\n",
    "        \n",
    "    \n",
    "        \n",
    "    return {\n",
    "        \"results_each_hyperparameter\": results,\n",
    "        \"results_according_k\": results_according_k,\n",
    "        \"best_mean\": best_mean_result,\n",
    "        \"best_mean_k_number\": best_mean_k_number,\n",
    "        \"best_mode\": best_mode_result,\n",
    "        \"best_mode_k_number\": best_mode_k_number,\n",
    "        \"best_mean_good_datasets\": best_mean_good_datasets,\n",
    "        \"best_mean_good_datasets_k_number\": best_mean_good_datasets_k_number,\n",
    "        \"best_mode_good_datasets\": best_mode_good_datasets,\n",
    "        \"best_mode_good_datasets_k_number\": best_mode_good_datasets_k_number,\n",
    "        \"best_result_using_hyperparameter_directly\": best_result_using_hyperparameter_directly\n",
    "        \n",
    "    }\n",
    "#     print(results)\n",
    "\n",
    "#     result = {\n",
    "#         \"results_each_hyperparameter\": results,\n",
    "#         \"results_according_k\"\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     return results\n",
    "final_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  acute-inflammations_1556.csv\n",
      "1  -  allbp_40707.csv\n",
      "2  -  analcatdata_authorship_458.csv\n",
      "3  -  analcatdata_challenger_1013.csv\n",
      "4  -  analcatdata_chlamydia_875.csv\n",
      "5  -  analcatdata_creditscore_461.csv\n",
      "6  -  analcatdata_germangss_1025.csv\n",
      "7  -  analcatdata_happiness_40709.csv\n",
      "8  -  analcatdata_lawsuit_450.csv\n",
      "9  -  analcatdata_vineyard_724.csv\n",
      "10  -  analcatdata_wildcat_748.csv\n",
      "11  -  ar1_1059.csv\n",
      "12  -  ar4_1061.csv\n",
      "13  -  ar6_1064.csv\n",
      "14  -  autoPrice_756.csv\n",
      "15  -  autoUniv-au6-400_1551.csv\n",
      "16  -  autoUniv-au7-500_1554.csv\n",
      "17  -  auto_price_745.csv\n",
      "18  -  backache_463.csv\n",
      "19  -  badges2_1121.csv\n",
      "20  -  blogger_1463.csv\n",
      "21  -  blood-transfusion-service-center_1464.csv\n",
      "22  -  bodyfat_778.csv\n",
      "23  -  breast-cancer-dropped-missing-attributes-values_23499.csv\n",
      "24  -  breast-tissue_1465.csv\n",
      "25  -  breast-tissue_1559.csv\n",
      "26  -  calendarDOW_40663.csv\n",
      "27  -  car-evaluation_40664.csv\n",
      "28  -  cardiotocography_1466.csv\n",
      "29  -  cars1_40700.csv\n",
      "30  -  CastMetal1_1447.csv\n",
      "31  -  chatfield_4_820.csv\n",
      "32  -  chscase_census2_909.csv\n",
      "33  -  chscase_census3_908.csv\n",
      "34  -  chscase_census4_907.csv\n",
      "35  -  chscase_census5_906.csv\n",
      "36  -  chscase_census6_900.csv\n",
      "37  -  chscase_geyser1_895.csv\n",
      "38  -  chscase_vine2_814.csv\n",
      "39  -  clean1_40665.csv\n",
      "40  -  cleveland-nominal_40711.csv\n",
      "41  -  cleve_40710.csv\n",
      "42  -  cloud_860.csv\n",
      "43  -  collins_987.csv\n",
      "44  -  corral_40669.csv\n",
      "45  -  CostaMadre1_1446.csv\n",
      "47  -  datatrieve_1075.csv\n",
      "49  -  diggle_table_a2_818.csv\n",
      "50  -  ecoli_1011.csv\n",
      "51  -  ecoli_39.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      " * Warning: The least populated class in y has only 2 members, which is less than n_splits=5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52  -  ecoli_40671.csv\n",
      "54  -  fertility_1473.csv\n",
      "55  -  fri_c0_100_10_808.csv\n",
      "56  -  fri_c0_100_25_889.csv\n",
      "57  -  fri_c0_100_50_850.csv\n",
      "58  -  fri_c0_100_5_754.csv\n",
      "59  -  fri_c0_250_10_763.csv\n",
      "60  -  fri_c0_250_25_773.csv\n",
      "61  -  fri_c0_250_50_732.csv\n",
      "62  -  fri_c0_250_5_776.csv\n",
      "63  -  fri_c0_500_10_943.csv\n",
      "64  -  fri_c0_500_25_926.csv\n",
      "65  -  fri_c0_500_50_888.csv\n",
      "66  -  fri_c0_500_5_884.csv\n",
      "67  -  fri_c1_100_10_789.csv\n",
      "68  -  fri_c1_100_25_812.csv\n",
      "69  -  fri_c1_100_50_876.csv\n",
      "70  -  fri_c1_100_5_829.csv\n",
      "71  -  fri_c1_250_10_935.csv\n",
      "72  -  fri_c1_250_25_746.csv\n",
      "73  -  fri_c1_250_50_769.csv\n",
      "74  -  fri_c1_250_5_730.csv\n",
      "75  -  fri_c1_500_10_824.csv\n",
      "76  -  fri_c1_500_25_779.csv\n",
      "77  -  fri_c1_500_50_766.csv\n",
      "78  -  fri_c1_500_5_870.csv\n",
      "79  -  fri_c2_100_10_762.csv\n",
      "80  -  fri_c2_100_25_775.csv\n",
      "81  -  fri_c2_100_50_922.csv\n",
      "82  -  fri_c2_100_5_726.csv\n",
      "83  -  fri_c2_250_10_830.csv\n",
      "84  -  fri_c2_250_25_794.csv\n",
      "85  -  fri_c2_250_50_877.csv\n",
      "86  -  fri_c2_250_5_911.csv\n",
      "87  -  fri_c2_500_10_869.csv\n",
      "88  -  fri_c2_500_25_879.csv\n",
      "89  -  fri_c2_500_50_920.csv\n",
      "90  -  fri_c2_500_5_792.csv\n",
      "91  -  fri_c3_100_10_783.csv\n",
      "92  -  fri_c3_100_25_768.csv\n",
      "93  -  fri_c3_100_50_716.csv\n",
      "94  -  fri_c3_100_5_916.csv\n",
      "95  -  fri_c3_250_10_793.csv\n",
      "96  -  fri_c3_250_25_832.csv\n",
      "97  -  fri_c3_250_50_873.csv\n",
      "98  -  fri_c3_250_5_744.csv\n",
      "99  -  fri_c3_500_10_936.csv\n",
      "100  -  fri_c3_500_25_896.csv\n",
      "101  -  fri_c3_500_50_937.csv\n",
      "102  -  fri_c3_500_5_749.csv\n",
      "103  -  fri_c4_100_100_828.csv\n",
      "104  -  fri_c4_100_10_878.csv\n",
      "105  -  fri_c4_100_25_868.csv\n",
      "106  -  fri_c4_100_50_932.csv\n",
      "107  -  fri_c4_250_100_834.csv\n",
      "108  -  fri_c4_250_10_863.csv\n",
      "109  -  fri_c4_250_25_933.csv\n",
      "110  -  fri_c4_250_50_918.csv\n",
      "111  -  fri_c4_500_100_742.csv\n",
      "112  -  fri_c4_500_10_855.csv\n",
      "113  -  fri_c4_500_25_838.csv\n",
      "114  -  fri_c4_500_50_805.csv\n",
      "115  -  fruitfly_714.csv\n",
      "116  -  glass_1005.csv\n",
      "117  -  glass_41.csv\n",
      "118  -  haberman_43.csv\n",
      "119  -  hayes-roth_329.csv\n",
      "120  -  hayes-roth_974.csv\n",
      "121  -  heart-h_1565.csv\n",
      "122  -  heart-long-beach_1512.csv\n",
      "123  -  heart-statlog_53.csv\n",
      "124  -  heart-switzerland_1513.csv\n",
      "125  -  ionosphere_59.csv\n",
      "126  -  iris_61.csv\n",
      "127  -  jEdit_4.0_4.2_1073.csv\n",
      "128  -  jEdit_4.2_4.3_1048.csv\n",
      "129  -  kc1-binary_1066.csv\n",
      "130  -  kc1-top5_1045.csv\n",
      "131  -  kc3_1065.csv\n",
      "132  -  KnuggetChase3_1448.csv\n",
      "133  -  KungChi3_1441.csv\n",
      "134  -  leaf_1482.csv\n",
      "135  -  LED-display-domain-7digit_40496.csv\n",
      "136  -  lowbwt_941.csv\n",
      "137  -  machine_cpu_733.csv\n",
      "138  -  mc2_1054.csv\n",
      "139  -  MeanWhile1_1449.csv\n",
      "140  -  mfeat-fourier_14.csv\n",
      "141  -  mfeat-karhunen_16.csv\n",
      "142  -  mfeat-pixel_40979.csv\n",
      "143  -  MindCave2_1450.csv\n",
      "144  -  monks-problems-2_334.csv\n",
      "145  -  mu284_880.csv\n",
      "146  -  mux6_40681.csv\n",
      "147  -  mw1_1071.csv\n",
      "148  -  no2_886.csv\n",
      "149  -  parkinsons_1488.csv\n",
      "150  -  pc1_req_1167.csv\n",
      "151  -  planning-relax_1490.csv\n",
      "152  -  plasma_retinol_915.csv\n",
      "153  -  pm10_750.csv\n",
      "154  -  prnn_fglass_952.csv\n",
      "155  -  prnn_fglass_996.csv\n",
      "156  -  prnn_synth_464.csv\n",
      "157  -  pwLinear_721.csv\n",
      "158  -  qsar-biodeg_1494.csv\n",
      "159  -  qualitative-bankruptcy_1495.csv\n",
      "160  -  rabe_266_782.csv\n",
      "161  -  rmftsa_sleepdata_679.csv\n",
      "162  -  robot-failures-lp4_1519.csv\n",
      "163  -  robot-failures-lp5_1520.csv\n",
      "164  -  sa-heart_1498.csv\n",
      "165  -  seeds_1499.csv\n",
      "166  -  seismic-bumps_1500.csv\n",
      "167  -  servo_747.csv\n",
      "168  -  sleuth_case2002_902.csv\n",
      "169  -  Smartphone-Based_Recognition_of_Human_Activities_4153.csv\n",
      "170  -  solar-flare_40686.csv\n",
      "171  -  sonar_40.csv\n",
      "172  -  SPECTF_1600.csv\n",
      "173  -  SPECTF_337.csv\n",
      "174  -  SPECT_336.csv\n",
      "175  -  steel-plates-fault_1504.csv\n",
      "176  -  synthetic_control_377.csv\n",
      "177  -  tae_48.csv\n",
      "178  -  tae_955.csv\n",
      "179  -  teachingAssistant_1115.csv\n",
      "180  -  tecator_851.csv\n",
      "181  -  thoracic-surgery_1506.csv\n",
      "182  -  thyroid-allhypo_40476.csv\n",
      "183  -  thyroid-new_40682.csv\n",
      "184  -  transplant_885.csv\n",
      "185  -  triazines_788.csv\n",
      "186  -  TuningSVMs_41976.csv\n",
      "187  -  TuningSVMs_41977.csv\n",
      "188  -  user-knowledge_1508.csv\n",
      "189  -  vertebra-column_1524.csv\n",
      "190  -  veteran_719.csv\n",
      "191  -  vinnie_860.csv\n",
      "192  -  visualizing_environmental_736.csv\n",
      "193  -  visualizing_galaxy_925.csv\n",
      "194  -  wholesale-customers_1511.csv\n",
      "195  -  wine-quality-red_40691.csv\n",
      "196  -  wine_187.csv\n",
      "197  -  wine_973.csv\n",
      "198  -  wisconsin_753.csv\n",
      "199  -  yeast_181.csv\n",
      "200  -  zoo_965.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 46-47-48 com problemas\n",
    "for i in range(0, len(onlyfiles)):\n",
    "    d1 = getDatasetInfo(onlyfiles[i])\n",
    "    d1_mfe = getDatasetMfeInfo(onlyfiles[i])\n",
    "    \n",
    "    if(d1 == ''):\n",
    "        continue\n",
    "        \n",
    "    print(i, ' - ', d1['name'])\n",
    "                        \n",
    "    if(d1):\n",
    "        d = {\n",
    "            \"dataset\": onlyfiles[i],\n",
    "            \"default_result\": d1['default_params_result'],\n",
    "#             'results_each_hyperparameter': getBestNHyperparams(onlyfiles[i], 10)\n",
    "        }\n",
    "        \n",
    "#         print('Dataset: ', onlyfiles[i])\n",
    "#         print('Resultado default: ', d1['default_params_result'])\n",
    "#         print('\\n')\n",
    "        # O ultimo parametro é o N (N datasets mais semelhantes de acordo com as mfes)\n",
    "        answer = getBestNHyperparams(onlyfiles[i], 10)\n",
    "        d.update(answer)\n",
    "        final_result.append(d)\n",
    "#         print('---------------------')\n",
    "        \n",
    "\n",
    "# print(final_result)\n",
    "\n",
    "# print('Quantidade de datasets otimizados pelo metalearning: ', optimized_datasets)\n",
    "with open('final_result.json', 'w') as outfile:\n",
    "    json.dump(final_result, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ULTIMA PARTE - Analisando os resultados\n",
    "file = open('final_result.json')\n",
    "d = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets:  198\n",
      "Improved Datasets with Mean:  151\n",
      "Improved Datasets with Mode:  141\n",
      "Improved Datasets with mean using good datasets:  160\n",
      "Improved Datasets with mode using good datasets:  153\n",
      "Improved Datasets Directly:  160\n"
     ]
    }
   ],
   "source": [
    "# Quantos datasets tiveram os resultados melhorados\n",
    "# Em média, quantos Ks eram necessários para melhorar os resultados\n",
    "\n",
    "print('Number of datasets: ', len(d))\n",
    "\n",
    "improved_datasets_mean = 0\n",
    "improved_datasets_mode = 0\n",
    "improved_datasets_directly = 0\n",
    "\n",
    "improved_datasets_mean_good = 0\n",
    "improved_datasets_mode_good = 0\n",
    "\n",
    "mean_count_according_k = []\n",
    "mode_count_according_k = []\n",
    "mean_good_count_according_k = []\n",
    "mode_good_count_according_k = []\n",
    "\n",
    "for i in range(0, len(d)):\n",
    "    if(d[i]['best_mean'] > d[i]['default_result']):\n",
    "        improved_datasets_mean += 1\n",
    "    if(d[i]['best_mode'] > d[i]['default_result']):\n",
    "        improved_datasets_mode += 1\n",
    "    if(d[i]['best_result_using_hyperparameter_directly'] > d[i]['default_result']):\n",
    "        improved_datasets_directly += 1\n",
    "        \n",
    "    if(d[i]['best_mean_good_datasets'] > d[i]['default_result']):\n",
    "        improved_datasets_mean_good += 1\n",
    "    if(d[i]['best_mode_good_datasets'] > d[i]['default_result']):\n",
    "        improved_datasets_mode_good += 1\n",
    "    \n",
    "    for j in d[i]['results_according_k']:\n",
    "        if(j['mean'] > d[i]['default_result']):\n",
    "            mean_count_according_k.append(j['k'])\n",
    "        if(j['mode'] > d[i]['default_result']):\n",
    "            mode_count_according_k.append(j['k'])\n",
    "        if(j['mean_good_datasets'] > d[i]['default_result']):\n",
    "            mean_good_count_according_k.append(j['k'])\n",
    "        if(j['mode_good_datasets'] > d[i]['default_result']):\n",
    "            mode_good_count_according_k.append(j['k'])\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "print('Improved Datasets with Mean: ', improved_datasets_mean)\n",
    "print('Improved Datasets with Mode: ', improved_datasets_mode)\n",
    "print('Improved Datasets with mean using good datasets: ', improved_datasets_mean_good)\n",
    "print('Improved Datasets with mode using good datasets: ', improved_datasets_mode_good)\n",
    "print('Improved Datasets Directly: ', improved_datasets_directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 0.2}\n",
      "0  -  acute-inflammations_1556.csv\n",
      "95.83333333333334  -  100.0\n",
      "1  -  allbp_40707.csv\n",
      "97.61399687318846  -  97.45488081226833\n",
      "2  -  analcatdata_authorship_458.csv\n",
      "96.79487179487178  -  97.38517892364045\n",
      "3  -  analcatdata_challenger_1013.csv\n",
      "86.34920634920634  -  93.49206349206348\n",
      "4  -  analcatdata_chlamydia_875.csv\n",
      "82.0  -  84.00000000000001\n",
      "5  -  analcatdata_creditscore_461.csv\n",
      "99.0  -  99.0\n",
      "6  -  analcatdata_germangss_1025.csv\n",
      "93.5  -  92.0\n",
      "7  -  analcatdata_happiness_40709.csv\n",
      "48.33333333333333  -  63.33333333333333\n",
      "8  -  analcatdata_lawsuit_450.csv\n",
      "95.4644412191582  -  94.70246734397678\n",
      "9  -  analcatdata_vineyard_724.csv\n",
      "53.427133379089454  -  62.182566918325335\n",
      "10  -  analcatdata_wildcat_748.csv\n",
      "75.41666666666667  -  75.98484848484848\n",
      "11  -  ar1_1059.csv\n",
      "93.36666666666666  -  91.73333333333333\n",
      "12  -  ar4_1061.csv\n",
      "84.11255411255411  -  83.20346320346322\n",
      "13  -  ar6_1064.csv\n",
      "85.19047619047619  -  89.1904761904762\n",
      "14  -  autoPrice_756.csv\n",
      "91.16935483870968  -  91.79435483870968\n",
      "15  -  autoUniv-au6-400_1551.csv\n",
      "36.5  -  33.24999999999999\n",
      "16  -  autoUniv-au7-500_1554.csv\n",
      "46.19999999999999  -  45.800000000000004\n",
      "17  -  auto_price_745.csv\n",
      "91.16935483870968  -  91.79435483870968\n",
      "18  -  backache_463.csv\n",
      "84.44444444444444  -  86.1111111111111\n",
      "19  -  badges2_1121.csv\n",
      "100.0  -  100.0\n",
      "20  -  blogger_1463.csv\n",
      "85.0  -  78.0\n",
      "21  -  blood-transfusion-service-center_1464.csv\n",
      "67.6599552572707  -  71.40313199105147\n",
      "22  -  bodyfat_778.csv\n",
      "99.6078431372549  -  99.6078431372549\n",
      "23  -  breast-cancer-dropped-missing-attributes-values_23499.csv\n",
      "63.883116883116884  -  72.9090909090909\n",
      "24  -  breast-tissue_1465.csv\n",
      "43.290043290043286  -  40.476190476190474\n",
      "25  -  breast-tissue_1559.csv\n",
      "60.38961038961038  -  59.48051948051947\n",
      "26  -  calendarDOW_40663.csv\n",
      "57.6012658227848  -  53.84493670886077\n",
      "27  -  car-evaluation_40664.csv\n",
      "78.36826673368519  -  77.72907765770294\n",
      "28  -  cardiotocography_1466.csv\n",
      "100.0  -  100.0\n",
      "29  -  cars1_40700.csv\n",
      "86.22200584225901  -  83.1548198636806\n",
      "30  -  CastMetal1_1447.csv\n",
      "85.93473193473194  -  84.4102564102564\n",
      "31  -  chatfield_4_820.csv\n",
      "86.80851063829789  -  87.6595744680851\n",
      "32  -  chscase_census2_909.csv\n",
      "49.25  -  50.24999999999999\n",
      "33  -  chscase_census3_908.csv\n",
      "45.24999999999999  -  44.74999999999999\n",
      "34  -  chscase_census4_907.csv\n",
      "50.25000000000001  -  52.75000000000001\n",
      "35  -  chscase_census5_906.csv\n",
      "51.24999999999999  -  51.5\n",
      "36  -  chscase_census6_900.csv\n",
      "50.74999999999999  -  51.74999999999999\n",
      "37  -  chscase_geyser1_895.csv\n",
      "83.4040404040404  -  86.95959595959594\n",
      "38  -  chscase_vine2_814.csv\n",
      "48.53580416380691  -  52.18714253031342\n",
      "39  -  clean1_40665.csv\n",
      "89.7390350877193  -  89.7390350877193\n",
      "40  -  cleveland-nominal_40711.csv\n",
      "53.147540983606554  -  56.76502732240437\n",
      "41  -  cleve_40710.csv\n",
      "78.24043715846996  -  79.8743169398907\n",
      "42  -  cloud_860.csv\n",
      "68.52813852813853  -  64.84848484848484\n",
      "43  -  collins_987.csv\n",
      "94.0  -  94.0\n",
      "44  -  corral_40669.csv\n",
      "100.0  -  100.0\n",
      "45  -  CostaMadre1_1446.csv\n",
      "84.45197740112992  -  86.14124293785311\n",
      "46  -  dataset-autoHorse_fixed_42223.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Warning: The least populated class in y has only 1 members, which is less than n_splits=2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  -  0.0\n",
      "47  -  datatrieve_1075.csv\n",
      "86.92307692307693  -  90.76923076923077\n",
      "49  -  diggle_table_a2_818.csv\n",
      "100.0  -  100.0\n",
      "50  -  ecoli_1011.csv\n",
      "94.04302019315189  -  95.23266022827042\n",
      "51  -  ecoli_39.csv\n",
      "86.60714285714286  -  86.30952380952381\n",
      "52  -  ecoli_40671.csv\n",
      "84.70396270396272  -  85.93473193473194\n",
      "53  -  Engine1_4340.csv\n",
      "54  -  fertility_1473.csv\n",
      "86.0  -  86.0\n",
      "55  -  fri_c0_100_10_808.csv\n",
      "85.0  -  82.0\n",
      "56  -  fri_c0_100_25_889.csv\n",
      "70.0  -  65.0\n",
      "57  -  fri_c0_100_50_850.csv\n",
      "70.0  -  65.00000000000001\n",
      "58  -  fri_c0_100_5_754.csv\n",
      "87.00000000000001  -  84.00000000000001\n",
      "59  -  fri_c0_250_10_763.csv\n",
      "82.4  -  84.80000000000001\n",
      "60  -  fri_c0_250_25_773.csv\n",
      "85.2  -  83.6\n",
      "61  -  fri_c0_250_50_732.csv\n",
      "80.0  -  79.60000000000001\n",
      "62  -  fri_c0_250_5_776.csv\n",
      "83.60000000000001  -  83.6\n",
      "63  -  fri_c0_500_10_943.csv\n",
      "86.8  -  87.20000000000002\n",
      "64  -  fri_c0_500_25_926.csv\n",
      "83.0  -  84.59999999999998\n",
      "65  -  fri_c0_500_50_888.csv\n",
      "84.00000000000001  -  86.0\n",
      "66  -  fri_c0_500_5_884.csv\n",
      "88.6  -  87.6\n",
      "67  -  fri_c1_100_10_789.csv\n",
      "79.0  -  82.0\n",
      "68  -  fri_c1_100_25_812.csv\n",
      "85.0  -  86.00000000000001\n",
      "69  -  fri_c1_100_50_876.csv\n",
      "71.0  -  68.0\n",
      "70  -  fri_c1_100_5_829.csv\n",
      "80.0  -  81.0\n",
      "71  -  fri_c1_250_10_935.csv\n",
      "88.79999999999998  -  90.0\n",
      "72  -  fri_c1_250_25_746.csv\n",
      "87.6  -  90.39999999999999\n",
      "73  -  fri_c1_250_50_769.csv\n",
      "89.6  -  88.80000000000001\n",
      "74  -  fri_c1_250_5_730.csv\n",
      "92.00000000000001  -  92.8\n",
      "75  -  fri_c1_500_10_824.csv\n",
      "90.19999999999999  -  89.8\n",
      "76  -  fri_c1_500_25_779.csv\n",
      "87.4  -  87.6\n",
      "77  -  fri_c1_500_50_766.csv\n",
      "86.19999999999999  -  88.2\n",
      "78  -  fri_c1_500_5_870.csv\n",
      "90.0  -  90.0\n",
      "79  -  fri_c2_100_10_762.csv\n",
      "73.00000000000001  -  76.0\n",
      "80  -  fri_c2_100_25_775.csv\n",
      "80.0  -  81.0\n",
      "81  -  fri_c2_100_50_922.csv\n",
      "86.0  -  86.99999999999999\n",
      "82  -  fri_c2_100_5_726.csv\n",
      "80.0  -  81.0\n",
      "83  -  fri_c2_250_10_830.csv\n",
      "90.40000000000002  -  89.60000000000001\n",
      "84  -  fri_c2_250_25_794.csv\n",
      "87.6  -  87.20000000000002\n",
      "85  -  fri_c2_250_50_877.csv\n",
      "87.6  -  85.60000000000001\n",
      "86  -  fri_c2_250_5_911.csv\n",
      "87.20000000000002  -  87.99999999999999\n",
      "87  -  fri_c2_500_10_869.csv\n",
      "92.2  -  92.4\n",
      "88  -  fri_c2_500_25_879.csv\n",
      "88.6  -  88.4\n",
      "89  -  fri_c2_500_50_920.csv\n",
      "91.4  -  89.60000000000001\n",
      "90  -  fri_c2_500_5_792.csv\n",
      "91.60000000000001  -  91.60000000000001\n",
      "91  -  fri_c3_100_10_783.csv\n",
      "75.0  -  75.0\n",
      "92  -  fri_c3_100_25_768.csv\n",
      "71.00000000000001  -  76.99999999999999\n",
      "93  -  fri_c3_100_50_716.csv\n",
      "76.0  -  78.0\n",
      "94  -  fri_c3_100_5_916.csv\n",
      "84.00000000000001  -  83.0\n",
      "95  -  fri_c3_250_10_793.csv\n",
      "90.8  -  90.0\n",
      "96  -  fri_c3_250_25_832.csv\n",
      "86.8  -  84.80000000000001\n",
      "97  -  fri_c3_250_50_873.csv\n",
      "85.2  -  82.0\n",
      "98  -  fri_c3_250_5_744.csv\n",
      "87.20000000000002  -  84.00000000000001\n",
      "99  -  fri_c3_500_10_936.csv\n",
      "89.8  -  88.2\n",
      "100  -  fri_c3_500_25_896.csv\n",
      "89.6  -  87.80000000000001\n",
      "101  -  fri_c3_500_50_937.csv\n",
      "89.0  -  85.2\n",
      "102  -  fri_c3_500_5_749.csv\n",
      "89.2  -  89.2\n",
      "103  -  fri_c4_100_100_828.csv\n",
      "76.0  -  73.00000000000001\n",
      "104  -  fri_c4_100_10_878.csv\n",
      "77.0  -  76.99999999999999\n",
      "105  -  fri_c4_100_25_868.csv\n",
      "74.0  -  81.00000000000001\n",
      "106  -  fri_c4_100_50_932.csv\n",
      "69.0  -  68.0\n",
      "107  -  fri_c4_250_100_834.csv\n",
      "84.39999999999999  -  81.60000000000001\n",
      "108  -  fri_c4_250_10_863.csv\n",
      "82.0  -  84.80000000000001\n",
      "109  -  fri_c4_250_25_933.csv\n",
      "85.2  -  84.00000000000001\n",
      "110  -  fri_c4_250_50_918.csv\n",
      "78.0  -  77.60000000000001\n",
      "111  -  fri_c4_500_100_742.csv\n",
      "88.80000000000001  -  87.6\n",
      "112  -  fri_c4_500_10_855.csv\n",
      "86.6  -  88.00000000000001\n",
      "113  -  fri_c4_500_25_838.csv\n",
      "88.4  -  89.0\n",
      "114  -  fri_c4_500_50_805.csv\n",
      "87.6  -  86.19999999999999\n",
      "115  -  fruitfly_714.csv\n",
      "41.6  -  56.00000000000001\n",
      "116  -  glass_1005.csv\n",
      "81.74972314507197  -  86.42303433001108\n",
      "117  -  glass_41.csv\n",
      "76.17940199335548  -  73.37763012181617\n",
      "118  -  haberman_43.csv\n",
      "67.95875198307775  -  64.01903754627182\n",
      "119  -  hayes-roth_329.csv\n",
      "81.25  -  84.375\n",
      "120  -  hayes-roth_974.csv\n",
      "76.52421652421653  -  79.54415954415954\n",
      "121  -  heart-h_1565.csv\n",
      "63.284628872004674  -  68.03623611922852\n",
      "122  -  heart-long-beach_1512.csv\n",
      "34.5  -  32.99999999999999\n",
      "123  -  heart-statlog_53.csv\n",
      "79.62962962962963  -  80.74074074074075\n",
      "124  -  heart-switzerland_1513.csv\n",
      "29.366666666666664  -  31.900000000000002\n",
      "125  -  ionosphere_59.csv\n",
      "92.03621730382294  -  93.17505030181087\n",
      "126  -  iris_61.csv\n",
      "96.0  -  96.0\n",
      "127  -  jEdit_4.0_4.2_1073.csv\n",
      "68.5925925925926  -  69.68350168350167\n",
      "128  -  jEdit_4.2_4.3_1048.csv\n",
      "59.34468715290634  -  61.24768604220658\n",
      "129  -  kc1-binary_1066.csv\n",
      "64.13793103448275  -  66.89655172413794\n",
      "130  -  kc1-top5_1045.csv\n",
      "95.86206896551724  -  95.17241379310344\n",
      "131  -  kc3_1065.csv\n",
      "91.04634495938842  -  90.17677974199714\n",
      "132  -  KnuggetChase3_1448.csv\n",
      "80.91767881241566  -  80.944669365722\n",
      "133  -  KungChi3_1441.csv\n",
      "86.1  -  85.30000000000001\n",
      "134  -  leaf_1482.csv\n",
      "71.17647058823529  -  69.11764705882352\n",
      "135  -  LED-display-domain-7digit_40496.csv\n",
      "71.4  -  74.6\n",
      "136  -  lowbwt_941.csv\n",
      "73.5846372688478  -  76.24466571834992\n",
      "137  -  machine_cpu_733.csv\n",
      "87.57259001161441  -  90.42973286875726\n",
      "138  -  mc2_1054.csv\n",
      "70.17045454545455  -  73.31439393939394\n",
      "139  -  MeanWhile1_1449.csv\n",
      "87.33333333333333  -  86.94117647058823\n",
      "140  -  mfeat-fourier_14.csv\n",
      "83.5  -  82.6\n",
      "141  -  mfeat-karhunen_16.csv\n",
      "95.10000000000002  -  93.8\n",
      "142  -  mfeat-pixel_40979.csv\n",
      "96.4  -  96.05\n",
      "143  -  MindCave2_1450.csv\n",
      "75.2  -  69.60000000000001\n",
      "144  -  monks-problems-2_334.csv\n",
      "93.16666666666666  -  79.84159779614326\n",
      "145  -  mu284_880.csv\n",
      "90.08771929824562  -  89.73057644110276\n",
      "146  -  mux6_40681.csv\n",
      "100.0  -  94.49230769230769\n",
      "147  -  mw1_1071.csv\n",
      "92.05864197530865  -  91.07098765432099\n",
      "148  -  no2_886.csv\n",
      "65.0  -  62.79999999999999\n",
      "149  -  parkinsons_1488.csv\n",
      "81.53846153846153  -  80.51282051282051\n",
      "150  -  pc1_req_1167.csv\n",
      "66.5625  -  65.9375\n",
      "151  -  planning-relax_1490.csv\n",
      "59.36936936936937  -  57.73273273273273\n",
      "152  -  plasma_retinol_915.csv\n",
      "57.777777777777786  -  60.0\n",
      "153  -  pm10_750.csv\n",
      "60.0  -  55.00000000000001\n",
      "154  -  prnn_fglass_952.csv\n",
      "64.99446290143965  -  63.565891472868216\n",
      "155  -  prnn_fglass_996.csv\n",
      "66.91029900332227  -  65.99114064230342\n",
      "156  -  prnn_synth_464.csv\n",
      "83.60000000000001  -  82.4\n",
      "157  -  pwLinear_721.csv\n",
      "88.5  -  87.99999999999999\n",
      "158  -  qsar-biodeg_1494.csv\n",
      "85.87677725118483  -  86.35071090047394\n",
      "159  -  qualitative-bankruptcy_1495.csv\n",
      "100.0  -  98.79999999999998\n",
      "160  -  rabe_266_782.csv\n",
      "93.33333333333333  -  91.66666666666666\n",
      "161  -  rmftsa_sleepdata_679.csv\n",
      "34.174557627929225  -  34.46532759445241\n",
      "162  -  robot-failures-lp4_1519.csv\n",
      "75.90579710144928  -  81.05072463768114\n",
      "163  -  robot-failures-lp5_1520.csv\n",
      "62.15909090909092  -  63.95833333333334\n",
      "164  -  sa-heart_1498.csv\n",
      "67.74193548387098  -  65.35764375876579\n",
      "165  -  seeds_1499.csv\n",
      "90.47619047619048  -  90.47619047619048\n",
      "166  -  seismic-bumps_1500.csv\n",
      "90.47619047619048  -  90.47619047619048\n",
      "167  -  servo_747.csv\n",
      "95.77540106951872  -  92.7807486631016\n",
      "168  -  sleuth_case2002_902.csv\n",
      "59.19540229885057  -  66.64367816091954\n",
      "169  -  Smartphone-Based_Recognition_of_Human_Activities_4153.csv\n",
      "93.88888888888887  -  93.88888888888889\n",
      "170  -  solar-flare_40686.csv\n",
      "70.15873015873017  -  71.42857142857142\n",
      "171  -  sonar_40.csv\n",
      "72.1602787456446  -  71.16144018583043\n",
      "172  -  SPECTF_1600.csv\n",
      "81.64220824598183  -  82.3759608665269\n",
      "173  -  SPECTF_337.csv\n",
      "91.13871635610765  -  92.85300207039337\n",
      "174  -  SPECT_336.csv\n",
      "82.0125786163522  -  82.01956673654787\n",
      "175  -  steel-plates-fault_1504.csv\n",
      "89.04155513741287  -  88.99014125566481\n",
      "176  -  synthetic_control_377.csv\n",
      "97.83333333333333  -  96.33333333333334\n",
      "177  -  tae_48.csv\n",
      "68.66666666666667  -  58.15053763440859\n",
      "178  -  tae_955.csv\n",
      "81.33333333333333  -  72.10752688172043\n",
      "179  -  teachingAssistant_1115.csv\n",
      "53.63440860215054  -  51.61290322580645\n",
      "180  -  tecator_851.csv\n",
      "91.25  -  90.41666666666669\n",
      "181  -  thoracic-surgery_1506.csv\n",
      "82.5531914893617  -  82.5531914893617\n",
      "182  -  thyroid-allhypo_40476.csv\n",
      "69.39285714285714  -  69.89285714285714\n",
      "183  -  thyroid-new_40682.csv\n",
      "95.34883720930232  -  94.88372093023256\n",
      "184  -  transplant_885.csv\n",
      "90.14245014245014  -  90.14245014245014\n",
      "185  -  triazines_788.csv\n",
      "79.01849217638691  -  78.50640113798009\n",
      "186  -  TuningSVMs_41976.csv\n",
      "66.02822580645162  -  66.65322580645162\n",
      "187  -  TuningSVMs_41977.csv\n",
      "74.37499999999999  -  75.02016129032258\n",
      "188  -  user-knowledge_1508.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.84259259259257  -  88.0864197530864\n",
      "189  -  vertebra-column_1524.csv\n",
      "80.64516129032258  -  80.64516129032258\n",
      "190  -  veteran_719.csv\n",
      "61.32275132275132  -  64.92063492063492\n",
      "191  -  vinnie_860.csv\n",
      "79.21052631578948  -  80.52631578947368\n",
      "192  -  visualizing_environmental_736.csv\n",
      "58.61660079051383  -  63.16205533596838\n",
      "193  -  visualizing_galaxy_925.csv\n",
      "95.98076923076924  -  96.27884615384616\n",
      "194  -  wholesale-customers_1511.csv\n",
      "100.0  -  100.0\n",
      "195  -  wine-quality-red_40691.csv\n",
      "54.723354231974916  -  54.34659090909091\n",
      "196  -  wine_187.csv\n",
      "94.98412698412699  -  95.55555555555554\n",
      "197  -  wine_973.csv\n",
      "93.88888888888889  -  93.87301587301587\n",
      "198  -  wisconsin_753.csv\n",
      "46.41025641025641  -  54.64237516869096\n",
      "199  -  yeast_181.csv\n",
      "55.457047957047955  -  58.760806260806255\n",
      "200  -  zoo_965.csv\n",
      "97.0  -  99.0\n",
      "Optimized Datasets:  90\n"
     ]
    }
   ],
   "source": [
    "# Deadline, calcular a média dos hiperparametros dentre os 200 e checar quantos foram melhorados com isso\n",
    "file = open('result.json')\n",
    "d = json.load(file)\n",
    "\n",
    "hyperparam_deadline = {'max_depth': 0, 'min_child_weight': 0, 'gamma': 0, 'subsample': 0, 'colsample_bytree': 0}\n",
    "\n",
    "\n",
    "print(d['datasets'][0]['params'])\n",
    "for i in d['datasets']:\n",
    "#     print(i['params'])\n",
    "    hyperparam_deadline['max_depth'] += i['params']['max_depth']\n",
    "    hyperparam_deadline['min_child_weight'] += i['params']['min_child_weight']\n",
    "    hyperparam_deadline['gamma'] += i['params']['gamma']\n",
    "    hyperparam_deadline['subsample'] += i['params']['subsample']\n",
    "    hyperparam_deadline['colsample_bytree'] += i['params']['colsample_bytree']\n",
    "\n",
    "hyperparam_deadline['max_depth'] = int(round(hyperparam_deadline['max_depth']/len(d['datasets'])))\n",
    "hyperparam_deadline['min_child_weight'] /= len(d['datasets'])\n",
    "hyperparam_deadline['gamma'] /= len(d['datasets'])\n",
    "hyperparam_deadline['subsample'] /= len(d['datasets'])\n",
    "hyperparam_deadline['colsample_bytree'] /= len(d['datasets'])\n",
    "\n",
    "hyperparam_deadline['max_depth'] = [hyperparam_deadline['max_depth']]\n",
    "hyperparam_deadline['min_child_weight'] = [hyperparam_deadline['min_child_weight']]\n",
    "hyperparam_deadline['gamma'] = [hyperparam_deadline['gamma']]\n",
    "hyperparam_deadline['subsample'] = [hyperparam_deadline['subsample']]\n",
    "hyperparam_deadline['colsample_bytree'] = [hyperparam_deadline['colsample_bytree']]\n",
    "\n",
    "optimized_datasets = 0\n",
    "\n",
    "    \n",
    "for i in range(0, len(onlyfiles)):\n",
    "    if(i == 48):\n",
    "        continue\n",
    "    print(i, ' - ', onlyfiles[i])\n",
    "    path = ('RealDatasets/' + onlyfiles[i])\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [*df.columns[:-1], 'target']\n",
    "    \n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df['target']\n",
    "    \n",
    "    k_folds = 5 \n",
    "    for j in df['target'].value_counts():\n",
    "        if(j < k_folds):\n",
    "            k_folds = j\n",
    "            break\n",
    "    \n",
    "    answer = 0\n",
    "    if(k_folds != 1):\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator = estimator,\n",
    "            param_grid = hyperparam_deadline,\n",
    "            cv = k_folds\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        answer = grid_search.best_score_*100\n",
    "    \n",
    "        answer_default = xgboost(df)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    if(answer_default[0] > answer):\n",
    "        optimized_datasets+=1\n",
    "    print(answer_default[0], ' - ', answer)\n",
    "    \n",
    "print('Optimized Datasets: ', optimized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 0.2}\n",
      "0  -  acute-inflammations_1556.csv\n",
      "95.83333333333334  -  95.83333333333334\n",
      "1  -  allbp_40707.csv\n",
      "97.61399687318846  -  97.5080366082878\n",
      "2  -  analcatdata_authorship_458.csv\n",
      "96.79487179487178  -  97.50563539025077\n",
      "3  -  analcatdata_challenger_1013.csv\n",
      "86.34920634920634  -  86.34920634920634\n",
      "4  -  analcatdata_chlamydia_875.csv\n",
      "82.0  -  81.0\n",
      "5  -  analcatdata_creditscore_461.csv\n",
      "99.0  -  99.0\n",
      "6  -  analcatdata_germangss_1025.csv\n",
      "93.5  -  94.0\n",
      "7  -  analcatdata_happiness_40709.csv\n",
      "48.33333333333333  -  46.666666666666664\n",
      "8  -  analcatdata_lawsuit_450.csv\n",
      "95.4644412191582  -  95.4644412191582\n",
      "9  -  analcatdata_vineyard_724.csv\n",
      "53.427133379089454  -  57.67787691603752\n",
      "10  -  analcatdata_wildcat_748.csv\n",
      "75.41666666666667  -  74.81060606060606\n",
      "11  -  ar1_1059.csv\n",
      "93.36666666666666  -  93.36666666666666\n",
      "12  -  ar4_1061.csv\n",
      "84.11255411255411  -  84.11255411255411\n",
      "13  -  ar6_1064.csv\n",
      "85.19047619047619  -  86.19047619047619\n",
      "14  -  autoPrice_756.csv\n",
      "91.16935483870968  -  91.16935483870968\n",
      "15  -  autoUniv-au6-400_1551.csv\n",
      "36.5  -  35.75000000000001\n",
      "16  -  autoUniv-au7-500_1554.csv\n",
      "46.19999999999999  -  47.599999999999994\n",
      "17  -  auto_price_745.csv\n",
      "91.16935483870968  -  91.16935483870968\n",
      "18  -  backache_463.csv\n",
      "84.44444444444444  -  83.88888888888889\n",
      "19  -  badges2_1121.csv\n",
      "100.0  -  100.0\n",
      "20  -  blogger_1463.csv\n",
      "85.0  -  85.0\n",
      "21  -  blood-transfusion-service-center_1464.csv\n",
      "67.6599552572707  -  70.73288590604027\n",
      "22  -  bodyfat_778.csv\n",
      "99.6078431372549  -  99.6078431372549\n",
      "23  -  breast-cancer-dropped-missing-attributes-values_23499.csv\n",
      "63.883116883116884  -  69.28571428571428\n",
      "24  -  breast-tissue_1465.csv\n",
      "43.290043290043286  -  42.38095238095238\n",
      "25  -  breast-tissue_1559.csv\n",
      "60.38961038961038  -  60.34632034632035\n",
      "26  -  calendarDOW_40663.csv\n",
      "57.6012658227848  -  55.101265822784804\n",
      "27  -  car-evaluation_40664.csv\n",
      "78.36826673368519  -  77.15104297562202\n",
      "28  -  cardiotocography_1466.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-87933853dae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0manswer_default\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a3eb5cb59d45>\u001b[0m in \u001b[0;36mxgboost\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    832\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programas\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Deadline, calcular a moda dos hiperparametros dentre os 200 e checar quantos foram melhorados com isso\n",
    "file = open('result_1.json')\n",
    "d = json.load(file)\n",
    "\n",
    "hyperparam_deadline = {'max_depth': [], 'min_child_weight': [], 'gamma': [], 'subsample': [], 'colsample_bytree': []}\n",
    "\n",
    "\n",
    "print(d['datasets'][0]['params'])\n",
    "for i in d['datasets']:\n",
    "#     print(i['params'])\n",
    "    hyperparam_deadline['max_depth'].append(i['params']['max_depth'])\n",
    "    hyperparam_deadline['min_child_weight'].append(i['params']['min_child_weight'])\n",
    "    hyperparam_deadline['gamma'].append(i['params']['gamma'])\n",
    "    hyperparam_deadline['subsample'].append(i['params']['subsample'])\n",
    "    hyperparam_deadline['colsample_bytree'].append(i['params']['colsample_bytree'])\n",
    "\n",
    "    \n",
    "hyperparam_deadline['max_depth'] = [max(set(hyperparam_deadline['max_depth']), key=hyperparam_deadline['max_depth'].count)]\n",
    "hyperparam_deadline['min_child_weight'] = [max(set(hyperparam_deadline['min_child_weight']), key=hyperparam_deadline['min_child_weight'].count)]\n",
    "hyperparam_deadline['gamma'] = [max(set(hyperparam_deadline['gamma']), key=hyperparam_deadline['gamma'].count)]\n",
    "hyperparam_deadline['subsample'] = [max(set(hyperparam_deadline['subsample']), key=hyperparam_deadline['subsample'].count)]\n",
    "hyperparam_deadline['colsample_bytree'] = [max(set(hyperparam_deadline['colsample_bytree']), key=hyperparam_deadline['colsample_bytree'].count)]\n",
    "\n",
    "optimized_datasets = 0\n",
    "    \n",
    "for i in range(0, len(onlyfiles)):\n",
    "    if(i == 48):\n",
    "        continue\n",
    "    print(i, ' - ', onlyfiles[i])\n",
    "    path = ('RealDatasets/' + onlyfiles[i])\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [*df.columns[:-1], 'target']\n",
    "    \n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df['target']\n",
    "    \n",
    "    k_folds = 5 \n",
    "    for j in df['target'].value_counts():\n",
    "        if(j < k_folds):\n",
    "            k_folds = j\n",
    "            break\n",
    "    \n",
    "    answer = 0\n",
    "    if(k_folds != 1):\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator = estimator,\n",
    "            param_grid = hyperparam_deadline,\n",
    "            cv = k_folds\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        answer = grid_search.best_score_*100\n",
    "    \n",
    "        answer_default = xgboost(df)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    if(answer_default[0] > answer):\n",
    "        optimized_datasets+=1\n",
    "    print(answer_default[0], ' - ', answer)\n",
    "    \n",
    "print('Optimized Datasets: ', optimized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(a, x):\n",
    "    count = 0\n",
    "    for i in a:\n",
    "        if(i == x):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def plot(array, title):\n",
    "    b = [i for i in range(1, 11)]\n",
    "    a = [0 for i in range(0, 10)]\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        a[i] = frequency(array, i)\n",
    "    plt.title(title)\n",
    "    plt.bar(b, a)\n",
    "    \n",
    "\n",
    "plot(mean_count_according_k, 'Para cada K de 1 a 10, a frequencia de datasets que foram melhorados através da média dos hiperparâmetros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mode_count_according_k, 'Para cada K de 1 a 10, a frequencia de datasets que foram melhorados através da moda dos hiperparâmetros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mean_good_count_according_k, 'Para cada K de 1 a 10, a frequencia de datasets que foram melhorados através da média dos hiperparâmetros apenas utilizando datasets bons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mode_good_count_according_k, 'Para cada K de 1 a 10, a frequencia de datasets que foram melhorados através da moda dos hiperparâmetros apenas utilizando datasets bons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
